{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":2645886,"sourceType":"datasetVersion","datasetId":1608934}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Beyin Tümörü MRI Sınıflandırması — CNN & Transfer Learning\n\nBu proje kapsamında MR görüntülerinden **beyin tümörü sınıflandırması** yapılması hedeflenmiştir.  \nKullanılan veri setinde dört temel sınıf bulunmaktadır:  \n- **Glioma**  \n- **Meningioma**  \n- **Pituitary**  \n- **No Tumor**  \n\nBu çalışmada izlenen temel adımlar şunlardır:  \n1. Veri setinin yüklenmesi ve incelenmesi (EDA)  \n2. Train / Validation / Test ayrımı  \n3. CNN tabanlı baseline modelin oluşturulması  \n4. Transfer Learning (EfficientNet/ResNet) ile performans artırma  \n5. Modelin değerlendirilmesi: Accuracy/Loss, Confusion Matrix, Classification Report  \n6. Grad-CAM ile görselleştirme  \n7. Hiperparametre denemeleri (ör. learning rate, batch size, optimizer)  ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow as tf\nimport re, os\nfrom pathlib import Path\nimport os\nos.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"  \n\nfrom contextlib import redirect_stderr\nimport os, sys\n\nwith open(os.devnull, \"w\") as devnull, redirect_stderr(devnull):\n    import tensorflow as tf\n\ntf.get_logger().setLevel(\"ERROR\")\ntry:\n    from absl import logging\n    logging.set_verbosity(logging.ERROR)\nexcept Exception:\n    pass\n\nimport tensorflow as tf\ntf.get_logger().setLevel(\"ERROR\")\ntry:\n    from absl import logging\n    logging.set_verbosity(logging.ERROR)\nexcept Exception:\n    pass\n\n\nSEED = 42\ntf.keras.utils.set_random_seed(SEED)\n\nINPUT_DIR = Path(\"/kaggle/input\")\nassert INPUT_DIR.exists(), \"Kaggle ortamı görünmüyor.\"\n\ntop_level = [p for p in INPUT_DIR.iterdir() if p.is_dir()]\n\npat = re.compile(r\"brain[-_ ]?tumou?r\", re.I)\ncandidates = [p for p in top_level if pat.search(p.name)]\n\nprint(\"Aday kökler:\")\nfor c in candidates:\n    print(\"  -\", c)\n\ndef looks_like_brain_tumor_ds(p: Path):\n    tt = [p/\"Training\", p/\"training\", p/\"Train\", p/\"train\"]\n    te = [p/\"Testing\",  p/\"testing\",  p/\"Test\",  p/\"test\"]\n    return any(x.exists() for x in tt) or any(x.exists() for x in te)\n\nranked = sorted(candidates, key=lambda p: (not looks_like_brain_tumor_ds(p), p.name))\nbase_path = ranked[0] if ranked else None\n\nassert base_path is not None, \"Dataset kökü bulunamadı. Sağ panelden Add Data ile dataset'i ekleyin.\"\nprint(\"\\nSeçilen base_path:\", base_path)\n\nMAX_DEPTH = 2\nSAMPLE_N = 5\n\nfor d, subdirs, files in os.walk(str(base_path)):\n    # d ile base_path arasındaki relatif derinlik\n    rel = os.path.relpath(d, start=str(base_path))\n    depth = 0 if rel == \".\" else rel.count(os.sep) + 1\n    if depth <= MAX_DEPTH:\n        files_sorted = sorted(files)[:SAMPLE_N]\n        print(f\"Klasör: {d} | Alt klasör: {len(subdirs)} | Dosya: {len(files)}\")\n        if files_sorted:\n            print(\"  Örnek dosyalar:\", files_sorted)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Veri Seti Yapısı\n\nKaggle ortamında yüklenen veri seti başarıyla bulundu. Seçilen kök dizin:  \n`/kaggle/input/brain-tumor-mri-dataset`\n\nVeri seti iki ana bölümden oluşmaktadır:  \n- **Training**: Eğitim verileri  \n- **Testing**: Test verileri  \n\nHer bölümde dört sınıf için ayrı klasör bulunmaktadır:  \n- **pituitary**  \n- **notumor** (normalize edildikten sonra → `no_tumor`)  \n- **meningioma**  \n- **glioma**\n\n### Örnek Dosya Yapısı\n- `Training/pituitary` → 1457 görüntü (ör: *Tr-piTr_0000.jpg*)  \n- `Training/notumor` → 1595 görüntü (ör: *Tr-noTr_0000.jpg*)  \n- `Training/meningioma` → 1339 görüntü  \n- `Training/glioma` → 1321 görüntü  \n- `Testing/pituitary` → 300 görüntü  \n- `Testing/notumor` → 405 görüntü  \n- `Testing/meningioma` → 306 görüntü  \n- `Testing/glioma` → 300 görüntü  \n\nBöylece her sınıf için eğitim ve test görüntülerinin dağılımı net bir şekilde görülmektedir. Sonraki adımda bu yapıyı DataFrame’e aktararak sınıf isimlerini normalize edeceğiz.","metadata":{}},{"cell_type":"markdown","source":"## Veri Organizasyonu ve Sınıf İsimleri\n\nKullandığım Brain Tumor MRI veri seti genellikle şu iki yapıya sahiptir:  \n- `Training/glioma, meningioma, pituitary, no_tumor` ve `Testing/...` klasörleri  \n- veya doğrudan kök dizin altında `glioma, meningioma, pituitary, no_tumor` klasörleri  \n\nBu bölümde yapılan işlemler:  \n- Her görüntünün tam yolunu ve sınıf etiketini bir **DataFrame** içine toplamak  \n- Sınıf isimlerini normalize etmek (örneğin `no_tumor`, `notumor`, `no_tumor(1)` → **no_tumor**)  \n\nBu sayede veri setindeki etiketler **tutarlı** hale getirilmiş olur.","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport re\nfrom pathlib import Path\n\nLABELS = [\"glioma\", \"meningioma\", \"pituitary\", \"no_tumor\"]\n_PATTERNS = {\n    \"glioma\":      re.compile(r\"\\bgli(oma)?\\b\", re.I),\n    \"meningioma\":  re.compile(r\"\\bmeningi(oma)?\\b\", re.I),\n    \"pituitary\":   re.compile(r\"\\bpit(uitary)?\\b\", re.I),\n    \"no_tumor\":    re.compile(r\"\\b(no[_-]?\\s*tumou?r|notumor|no[_-]?tumor)\\b\", re.I),\n}\ndef normalize_label(name: str):\n    n = name.lower().strip()\n    n = re.sub(r\"[^a-z0-9_\\- ]\", \"\", n)  \n    for lab, pat in _PATTERNS.items():\n        if pat.search(n):\n            return lab\n    return None  \n\nIMG_EXTS = {\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tif\", \".tiff\", \".jfif\"}\n\ndef gather_images(root):\n    paths, labels, splits = [], [], []\n    p = Path(root)\n\n    train_dir = next((p / cand for cand in [\"Training\",\"training\",\"Train\",\"train\"] if (p / cand).exists()), None)\n    test_dir  = next((p / cand for cand in [\"Testing\",\"testing\",\"Test\",\"test\"] if (p / cand).exists()), None)\n\n    def scan_split(split_root: Path, split_name: str):\n        for cls_dir in sorted(split_root.iterdir()):\n            if not cls_dir.is_dir():\n                continue\n            cls = normalize_label(cls_dir.name)\n            if cls is None:\n                \n                continue\n            for img_path in cls_dir.rglob(\"*\"):\n                if img_path.is_file() and img_path.suffix.lower() in IMG_EXTS:\n                    paths.append(str(img_path))\n                    labels.append(cls)\n                    splits.append(split_name)\n\n    if train_dir:\n        scan_split(train_dir, \"train\")\n        if test_dir:\n            scan_split(test_dir, \"test\")\n    else:\n \n        scan_split(p, \"unknown\")\n\n    df = pd.DataFrame({\"image_path\": paths, \"label_name\": labels, \"split\": splits})\n    return df\n\ndf = gather_images(base_path)\n\ndf = df[df[\"label_name\"].isin(LABELS)].copy()\nclass_names = sorted(df[\"label_name\"].unique().tolist())\nclass_to_id = {c:i for i,c in enumerate(class_names)}\ndf[\"label\"] = df[\"label_name\"].map(class_to_id)\n\nprint(\"Sınıflar:\", class_names)\nprint(\"Toplam görüntü:\", len(df))\n\nprint(\"\\nSplit dağılımı:\")\nprint(df[\"split\"].value_counts())\n\nprint(\"\\nSınıf dağılımı (toplam):\")\nprint(df[\"label_name\"].value_counts())\n\ndf.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Veri Seti Özeti\n\nVeri setindeki toplam görüntü sayısı: **7023**\n\n### Split Dağılımı\n- **Train**: 5712 görüntü  \n- **Test**: 1311 görüntü  \n\n### Sınıf Dağılımı (toplam)\n- **No Tumor**: 2000  \n- **Pituitary**: 1757  \n- **Meningioma**: 1645  \n- **Glioma**: 1621  \n\nGörüldüğü gibi veri seti genel olarak **dengeli** bir dağılıma sahip.  \nEn çok görüntü “No Tumor” sınıfına, en az görüntü ise “Glioma” sınıfına aittir.  \n\nAyrıca her görüntünün dosya yolu, sınıf etiketi ve split bilgisi bir **DataFrame** içerisinde saklanmıştır. Bu sayede sonraki adımlarda verileri kolayca kullanabiliriz.","metadata":{}},{"cell_type":"markdown","source":"## Keşifsel Veri Analizi (EDA)\n\nBu aşamada veri setini daha yakından tanımak için görselleştirmeler yaptım:  \n\n- **Sınıf Dağılımı:** Her sınıftaki görüntü sayısını bar grafikte göstererek dengesizlik olup olmadığını kontrol ettim.  \n- **Örnek Görseller:** Her sınıftan rastgele seçilen birkaç görüntüyü grid halinde görselleştirdim.  \n\nBu sayede veri setindeki sınıfların boyutlarını ve görüntülerin genel görünümlerini inceleme fırsatım oldu.","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\ndf_train_all = df[df[\"split\"] == \"train\"].copy()\n\ncounts = (\n    df_train_all[\"label_name\"]\n    .value_counts()\n    .reindex(class_names, fill_value=0)  \n)\n\nplt.figure(figsize=(7,4))\ncounts.plot(kind=\"bar\")\nplt.title(\"Sınıf Dağılımı (Train)\")\nplt.xlabel(\"Sınıf\")\nplt.ylabel(\"Görüntü Sayısı\")\nplt.xticks(rotation=10)\nplt.tight_layout()\nplt.show()\n\ncounts  \n\nimport tensorflow as tf\n\nrows, cols = len(class_names), 4\nplt.figure(figsize=(cols*3, rows*3))\n\nfor i, cls in enumerate(class_names):\n    pool = df_train_all[df_train_all[\"label_name\"] == cls]\n    sample_paths = pool[\"image_path\"].sample(\n        min(cols, len(pool)), random_state=SEED\n    ).tolist()\n\n    for j, pth in enumerate(sample_paths):\n        img = tf.io.read_file(pth)\n        img = tf.io.decode_image(img, channels=3, expand_animations=False)\n        plt.subplot(rows, cols, i*cols + j + 1)\n        plt.imshow(img.numpy())\n        plt.axis(\"off\")\n        if j == 0:\n            plt.title(cls)\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"\n### Sınıf Dağılımı (Train)\nBar grafikte görüldüğü gibi dört sınıfta da görüntü sayısı birbirine yakındır:  \n- **No Tumor**: En fazla görüntüye sahip (~1600 civarı)  \n- **Meningioma** ve **Glioma**: Birbirine yakın sayıda  \n- **Pituitary**: Biraz daha az ama dengeli  \n\nBu dağılım, modelin herhangi bir sınıfı öğrenirken ciddi bir dengesizlik yaşamayacağını göstermektedir.\n\n### Örnek Görseller\nHer sınıftan rastgele birkaç görüntü seçilerek incelenmiştir:  \n- **Glioma**: Beyin dokusu içinde düzensiz, hacim kaplayan kitleler  \n- **Meningioma**: Genellikle daha sınırları belirgin tümör yapıları  \n- **No Tumor**: Normal beyin yapısı, tümör bulgusu yok  \n- **Pituitary**: Beynin alt kısmındaki hipofiz bölgesinde küçük kitleler  \n\nBu görseller sayesinde sınıflar arasındaki görsel farklar daha iyi anlaşılmış ve modelin hangi özelliklerden faydalanabileceği öngörülmüştür.","metadata":{}},{"cell_type":"markdown","source":"## Train / Validation / Test Ayrımı\n\nModelin değerlendirilmesinde adil bir yapı kurmak için veriler üç parçaya ayrılmıştır:\n\n- **Train seti**: Modelin öğrenme sürecinde kullandığı ana veri.\n- **Validation seti**: Training verisinin %15’i stratified (sınıf dengeli) şekilde ayrılmıştır. Bu set eğitim sırasında modelin doğruluğunu ve olası overfitting durumunu izlemek için kullanılmıştır.\n- **Test seti**: Dataset ile birlikte gelen *Testing* klasörü doğrudan bağımsız test seti olarak kullanılmıştır.\n\nBu ayrım sayesinde model hem eğitim, hem doğrulama, hem de bağımsız test verisi üzerinde ayrı ayrı değerlendirilebilmiştir.","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ndf_train_all = df[df[\"split\"] == \"train\"].copy()\ndf_test      = df[df[\"split\"] == \"test\"].copy()\n\ndf_train, df_val = train_test_split(\n    df_train_all,\n    test_size=0.15,\n    stratify=df_train_all[\"label\"],\n    random_state=SEED\n)\n\nprint(f\"Toplam: {len(df)} | Train: {len(df_train)} | Val: {len(df_val)} | Test: {len(df_test)}\")\n\nprint(\"\\nSınıf dağılımları (train/val/test):\")\nfor subset_name, subset in [(\"Train\", df_train), (\"Val\", df_val), (\"Test\", df_test)]:\n    print(subset_name, subset[\"label_name\"].value_counts().to_dict())\n\ndf_train.head(2)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Veri Seti İstatistikleri Yorumu\n\nToplam **7023** görüntüden oluşan veri seti üçe ayrılmıştır: 4855 train, 857 validation ve 1311 test.  \nSplit oranları dengeli olduğu için her aşamada yeterli sayıda örnek bulunmaktadır.\n\nSınıf bazında incelendiğinde:  \n- **No Tumor** sınıfı her sette en çok örneğe sahiptir.  \n- **Pituitary, Meningioma ve Glioma** sınıfları sayıca birbirine oldukça yakındır.  \n- Validation setinde de aynı oran korunmuştur (stratified split sayesinde).  \n\nBu durum modelin öğrenme süreci için avantajlıdır çünkü sınıf dengesizliği neredeyse yoktur. Yani model belirli bir sınıfa aşırı yönelmeden, tüm sınıfları benzer şekilde öğrenme şansına sahiptir.  ","metadata":{}},{"cell_type":"markdown","source":"## tf.data Pipeline\n\nBu aşamada veriler model için uygun forma getirilmiştir:  \n\n- Tüm görüntüler **(192 × 192)** boyutuna resize edilip **[0,1]** aralığına normalize edildi.  \n- Veri çeşitliliğini artırmak için basit **data augmentation** uygulandı: yatay/dikey çevirme, küçük açılarda döndürme ve yakınlaştırma.  \n- **Batching** ve **Prefetching** yöntemleri kullanılarak eğitim süreci hızlandırıldı ve GPU daha verimli kullanıldı.  ","metadata":{}},{"cell_type":"code","source":"IMG_SIZE = (192, 192)\nBATCH    = 32\nAUTOTUNE = tf.data.AUTOTUNE\nSEED     = 42\n\ndata_augment = tf.keras.Sequential([\n    tf.keras.layers.RandomFlip(\"horizontal\"), \n    tf.keras.layers.RandomRotation(0.08),     \n    tf.keras.layers.RandomZoom(0.1),\n    tf.keras.layers.RandomContrast(0.1),\n], name=\"augment\")\n\ndef load_img(path, label):\n    img = tf.io.read_file(path)\n    img = tf.io.decode_image(img, channels=3, expand_animations=False)\n    img.set_shape([None, None, 3])                 \n    img = tf.image.resize(img, IMG_SIZE)\n    img = tf.cast(img, tf.float32) / 255.0\n    return img, label\n\ndef make_ds(df_, augment=False, shuffle=False, cache=False):\n    ds = tf.data.Dataset.from_tensor_slices(\n        (df_[\"image_path\"].values, df_[\"label\"].values)\n    )\n    ds = ds.map(load_img, num_parallel_calls=AUTOTUNE)\n    if shuffle:\n        ds = ds.shuffle(2048, seed=SEED)\n    if augment:\n        ds = ds.map(lambda x, y: (data_augment(x, training=True), y),\n                    num_parallel_calls=AUTOTUNE)\n    if cache:\n        ds = ds.cache()\n    ds = ds.batch(BATCH).prefetch(AUTOTUNE)\n    return ds\n\ntrain_ds = make_ds(df_train, augment=True,  shuffle=True,  cache=False)  \nval_ds   = make_ds(df_val,   augment=False, shuffle=False, cache=True)\ntest_ds  = make_ds(df_test,  augment=False, shuffle=False, cache=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for images, labels in train_ds.take(1):\n    print(\"Batch görüntü boyutu:\", images.shape)\n    print(\"Batch label örnekleri:\", labels.numpy()[:10])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Pipeline Doğrulama\n\nİlk batch’in çıktısı incelendiğinde:  \n- Görüntülerin boyutu **(32, 192, 192, 3)** şeklindedir. Yani batch size 32, her görsel 192×192 piksel ve 3 kanallıdır (RGB).  \n- Örnek etiketler `[0 2 1 2 3 2 1 0 2 0]` şeklinde gelmiştir. Bu sayılar sınıf ID’lerini göstermektedir ve verilerin doğru şekilde etiketlendiğini doğrulamaktadır.  \n\nBu sonuçlar, pipeline’ın (resize, normalize, batch, label eşleştirme) beklendiği gibi çalıştığını göstermektedir.  ","metadata":{}},{"cell_type":"markdown","source":"## Baseline CNN\n\nİlk adımda basit bir CNN modeli kurularak referans performans elde edilmeye çalışılmıştır.  \n\n- Model 3 konvolüsyon bloğundan oluşmaktadır: **Conv2D → BatchNorm → ReLU → MaxPool**  \n- Sonrasında **Global Average Pooling → Dense(128) → Dropout(0.4) → Dense(num_classes, softmax)** yapısı kullanılmıştır.  \n- Kayıp fonksiyonu: **sparse_categorical_crossentropy**  \n- Optimizasyon algoritması: **Adam (learning rate = 1e-3)**  \n\nBu modelin amacı, daha ileri yöntemlere (ör. Transfer Learning) geçmeden önce temel bir kıyas noktası (baseline) oluşturmaktır.  ","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras import regularizers\n\nprint(\"IMG_SIZE =\", IMG_SIZE)\n\ndef _to_shape(img_size):\n    if isinstance(img_size, int):\n        return (img_size, img_size, 3)\n    else:\n        h, w = img_size\n        return (h, w, 3)\n\nreg = tf.keras.regularizers.l2(1e-4)\n\ndef build_baseline_l2():\n    inputs = tf.keras.Input(shape=_to_shape(IMG_SIZE))\n\n    x = tf.keras.layers.Conv2D(32, 3, padding=\"same\", kernel_regularizer=reg)(inputs)\n    x = tf.keras.layers.BatchNormalization()(x); x = tf.keras.layers.ReLU()(x)\n    x = tf.keras.layers.MaxPooling2D()(x)\n\n    x = tf.keras.layers.Conv2D(64, 3, padding=\"same\", kernel_regularizer=reg)(x)\n    x = tf.keras.layers.BatchNormalization()(x); x = tf.keras.layers.ReLU()(x)\n    x = tf.keras.layers.MaxPooling2D()(x)\n\n    x = tf.keras.layers.Conv2D(128, 3, padding=\"same\", kernel_regularizer=reg)(x)\n    x = tf.keras.layers.BatchNormalization()(x); x = tf.keras.layers.ReLU()(x)\n    x = tf.keras.layers.MaxPooling2D()(x)\n\n    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n    x = tf.keras.layers.Dense(128, activation=\"relu\", kernel_regularizer=reg)(x)\n    x = tf.keras.layers.Dropout(0.5)(x)\n\n    outputs = tf.keras.layers.Dense(len(class_names), activation=\"softmax\")(x)\n    model = tf.keras.Model(inputs, outputs, name=\"baseline_cnn_l2_gap\")\n    return model\n\nbaseline_l2 = build_baseline_l2()\nbaseline_l2.compile(optimizer=tf.keras.optimizers.Adam(1e-3),\n                    loss=\"sparse_categorical_crossentropy\",\n                    metrics=[\"accuracy\"])\nbaseline_l2.summary()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Baseline CNN — Model Özeti\n\nModel mimarisi üç adet Conv2D bloğu üzerine kurulmuştur. Her blokta **Conv2D → BatchNorm → ReLU → MaxPooling** sıralaması vardır.  \nSonrasında **GlobalAveragePooling → Dense(128) → Dropout(0.4) → Dense(4, softmax)** ile sınıflandırma yapılır.\n\n### Katman Özellikleri:\n- İlk Conv2D katmanı 32 filtre, ikinci 64 filtre, üçüncü 128 filtre kullanıyor.\n- Her Conv2D sonrası Batch Normalization ile öğrenme stabilize ediliyor.\n- GlobalAveragePooling2D, parametre sayısını azaltarak aşırı öğrenmeyi engelliyor.\n- Dense(128) ve Dropout(0.4) son katman öncesinde eklenmiş.\n\n### Parametre Sayısı:\n- **Toplam parametre:** 111,172  \n- **Eğitilebilir parametre:** 110,724  \n- **Eğitilemeyen parametre:** 448  \n\nBu yapı, eğitim için hafif ama anlamlı bir başlangıç modeli sunar.  \nAmaç, önce bu baseline CNN’den referans bir performans almak, ardından Transfer Learning ile iyileştirmektir.","metadata":{}},{"cell_type":"code","source":"EPOCHS = 10\ncallbacks = [\n    tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=3, restore_best_weights=True),\n    tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.3, patience=2, min_lr=1e-6),\n    tf.keras.callbacks.ModelCheckpoint(\"/kaggle/working/baseline_btmri.keras\",\n                                       monitor=\"val_loss\", save_best_only=True, verbose=1)\n]\n\nhistory = baseline_l2.fit(   \n    train_ds,\n    validation_data=val_ds,\n    epochs=EPOCHS,\n    callbacks=callbacks,\n    verbose=2\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Baseline CNN — Eğitim Sonuçları\n\nModel 10 epoch boyunca eğitildi ve sonuçlar şu şekilde gözlemlendi:\n\n- **Eğitim doğruluğu (train accuracy):** %61’den başlayıp, son epoch’ta yaklaşık **%81.6**’ya kadar yükseldi.  \n- **Doğrulama doğruluğu (val accuracy):** İlk başta %23 civarında çok düşükken, epoch 4’te %60 seviyesine çıktı, epoch 7’de zirve yaparak **%73.0**’a ulaştı. Sonrasında küçük dalgalanmalar olsa da %70 civarında kaldı.  \n- **Val loss:** Başlangıçta 2.15 gibi yüksek bir değerden, epoch 7’de **0.69**’a kadar düştü. Bu aşamada model en iyi halini kaydetti.  \n- Öğrenme oranı (learning rate) **ReduceLROnPlateau** sayesinde epoch 7’den sonra kademeli olarak düşürüldü (0.001 → 0.0003 → 0.00009). Bu da modelin daha dengeli öğrenmesini sağladı.  \n\n### Yorum:\n- Model, temel bir CNN için oldukça iyi bir performans gösterdi: **%73 doğrulama doğruluğu** elde edildi.  \n- Başta validation accuracy düşük kalsa da ilerleyen epoch’larda hızlı bir toparlanma yaşandı.  \n- Bir miktar dalgalanma gözlense de aşırı overfitting belirgin değil. Ancak daha ileri seviyede genelleme için Transfer Learning gibi yöntemlerle performans artırılması hedeflenebilir.","metadata":{}},{"cell_type":"markdown","source":"## Model Eğitimi: Accuracy & Loss Grafikleri\n\nEğitim süresince modelin başarımı iki temel metrik üzerinden takip edilmiştir:  \n\n- **Accuracy (doğruluk):** Modelin hem eğitim hem de doğrulama verisinde ne kadar doğru tahmin yaptığını gösterir.  \n- **Loss (kayıp):** Modelin tahminleri ile gerçek etiketler arasındaki hatayı ifade eder.  \n\nBu grafikler sayesinde:  \n- Eğitim ve doğrulama eğrileri karşılaştırılarak **overfitting** (aşırı öğrenme) ya da **underfitting** (yetersiz öğrenme) olup olmadığı gözlemlenebilir.  \n- Ayrıca **ReduceLROnPlateau** gibi öğrenme oranı ayarlayıcılarının modele nasıl etki ettiği daha net anlaşılabilir.  ","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\n\ndef _concat_histories(hist_list):\n    \"\"\"Birden fazla History nesnesini ardışık ekler (örn. fine-tune sonrası).\"\"\"\n    out = {\"accuracy\": [], \"val_accuracy\": [], \"loss\": [], \"val_loss\": []}\n    for h in hist_list:\n        for k in out.keys():\n            if k in h.history:\n                out[k].extend(h.history[k])\n            else:\n                out[k].extend([np.nan]*len(next(iter(h.history.values()))))\n    return out\n\nhistories = [history]\nH = _concat_histories(histories)\n\n\nplt.figure(figsize=(6.5,4.2))\nplt.plot(H[\"accuracy\"], label=\"train_acc\")\nplt.plot(H[\"val_accuracy\"], label=\"val_acc\")\nplt.title(\"Accuracy Eğrisi\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Accuracy\")\nplt.legend()\nplt.tight_layout()\nplt.savefig(\"/kaggle/working/accuracy_curve.png\", dpi=150)\nplt.show()\n\n\nplt.figure(figsize=(6.5,4.2))\nplt.plot(H[\"loss\"], label=\"train_loss\")\nplt.plot(H[\"val_loss\"], label=\"val_loss\")\nplt.title(\"Loss Eğrisi\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Loss\")\nplt.legend()\nplt.tight_layout()\nplt.savefig(\"/kaggle/working/loss_curve.png\", dpi=150)\nplt.show()\n\nprint(\"Grafikler kaydedildi:\",\n      \"/kaggle/working/accuracy_curve.png\",\n      \"/kaggle/working/loss_curve.png\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Model Eğitimi Sonuçlarının Yorumu\n\n- **Accuracy Eğrisi:**  \n  Eğitim doğruluğu her epoch’ta düzenli şekilde artarak %80’in üzerine çıkmıştır.  \n  Doğrulama (validation) doğruluğu ise dalgalı bir seyir izlese de genel olarak %70 civarında toplanmıştır.  \n  Bu durum, modelin öğrenebildiğini fakat validasyonda dalgalanmalar yaşadığını gösteriyor.  \n  Özellikle 7. epoch’ta `val_accuracy` %73’e çıkarak en yüksek değere ulaşmıştır.\n\n- **Loss Eğrisi:**  \n  Eğitim kaybı (train_loss) düzenli biçimde azalmıştır, bu da modelin train verisinde iyi öğrendiğini gösteriyor.  \n  Validation kaybı (val_loss) ise bazı epoch’larda keskin dalgalanmalar yapmıştır (ör. 5. ve 6. epoch).  \n  Ancak sonlara doğru val_loss tekrar düşerek daha istikrarlı bir seviyeye gelmiştir.\n\n- **Genel Değerlendirme:**  \n  Model eğitim verisini öğrenmiş, validation tarafında ise zaman zaman dalgalansa da sonunda toparlanmıştır.  \n  Öğrenme oranı (ReduceLROnPlateau sayesinde) epoch ilerledikçe düşürülmüş ve bu sayede 7. epoch sonrası val_loss iyileşmiştir.  \n  Bu tablo, modelin **erken durdurma (EarlyStopping)** ve **learning rate scheduler** kullanımı sayesinde aşırı ezberleme (overfitting) riskinin azaltıldığını göstermektedir.","metadata":{}},{"cell_type":"markdown","source":" ## Test Seti Performansı\n\nModelin gerçek performansı, daha önce hiç görmediği **test seti** üzerinde ölçülmüştür.  \nBu aşamada iki temel değerlendirme aracı kullanılmıştır:\n\n- **Classification Report**: Her sınıf için **precision, recall ve F1-score** değerlerini verir. Böylece hangi sınıfta modelin güçlü, hangi sınıfta zayıf olduğunu detaylı görebiliriz.  \n- **Confusion Matrix**: Modelin hangi örnekleri doğru, hangilerini yanlış sınıflandırdığını görsel olarak sunar. Sınıflar arası karışıklıkları tespit etmeye yardımcı olur.","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import classification_report, confusion_matrix\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ny_true = df_test[\"label\"].values\n\npreds = baseline_l2.predict(test_ds)          \nif preds.ndim == 2:\n    y_pred = preds.argmax(axis=1)\nelse:\n    y_pred = (preds > 0.5).astype(int).ravel()\n\nprint(classification_report(y_true, y_pred, target_names=class_names, digits=4))\n\ncm = confusion_matrix(y_true, y_pred)\nplt.figure(figsize=(6,5))\nsns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n            xticklabels=class_names, yticklabels=class_names)\nplt.xlabel(\"Tahmin\")\nplt.ylabel(\"Gerçek\")\nplt.title(\"Confusion Matrix (Test Seti)\")\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Test Seti Sonuçlarının Yorumu\n\nTest setinde genel doğruluk oranı **%73.9** olarak ölçüldü. Bu sonuç, baseline CNN modelinin hiç görmediği veriler üzerinde makul bir performans sergilediğini gösteriyor.\n\n- **Glioma**: Precision %90, recall %74 → Model glioma sınıfını tahmin ederken oldukça doğru (yüksek precision), ancak bazı glioma örneklerini kaçırmış (recall görece düşük).  \n- **Meningioma**: Precision %70, recall %25 → Bu sınıf en zayıf sonuçlara sahip. Model meningioma örneklerini sıklıkla diğer sınıflarla karıştırıyor.  \n- **No Tumor**: Precision %81, recall %92 → Tümör olmayan görüntülerde en başarılı sınıf. Model normal MR görüntülerini büyük oranda doğru tanımış.  \n- **Pituitary**: Precision %60, recall %99 → Model neredeyse tüm pituitary örneklerini yakalamış (çok yüksek recall), fakat bazılarını yanlış sınıflara da atamış (precision düşük).\n\n**Genel Yorum:**  \n- Model özellikle **meningioma sınıfında** zorlanıyor. Bu sınıfta ek veri artırma (data augmentation) ya da daha dengeli veri kullanımı faydalı olabilir.  \n- **No Tumor ve Pituitary** sınıflarında recall oldukça yüksek, yani model bu sınıfları kaçırmıyor.  \n","metadata":{}},{"cell_type":"markdown","source":"## Grad-CAM Görselleştirme\n\nBu bölümde **Grad-CAM** yöntemi kullanılarak modelin karar verirken MR görüntülerinde hangi bölgelere odaklandığı incelendi.  \n- **Amaç:** Modelin doğru sınıflandırmalarda gerçekten tümör bölgesine odaklanıp odaklanmadığını görmek.  \n- **Yanlış tahminlerde:** Modelin ilgisinin başka bir bölgeye kayıp kaymadığını gözlemlemek.  \n\nBu görselleştirmeler, modelin “neden böyle tahmin yaptı?” sorusuna kısmen yanıt vererek hata analizi için önemli içgörüler sağlar.","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom pathlib import Path\nimport random\n\n\nMODEL = baseline_l2  \n\nCONV_TYPES = (\n    tf.keras.layers.Conv2D,\n    tf.keras.layers.SeparableConv2D,\n    tf.keras.layers.DepthwiseConv2D,\n)\n\ndef get_last_conv_layer(model):\n    for layer in reversed(model.layers):\n        if isinstance(layer, CONV_TYPES):\n            return layer.name\n    raise ValueError(\"Modelde Conv2D tabanlı bir katman bulunamadı.\")\n\nlast_conv_name = get_last_conv_layer(MODEL)\nprint(\"Grad-CAM katmanı:\", last_conv_name)\n\ndef load_for_cam(img_path):\n    img = tf.io.read_file(img_path)\n    img = tf.io.decode_image(img, channels=3, expand_animations=False)\n    img.set_shape([None, None, 3])\n    img = tf.image.resize(img, IMG_SIZE)\n    img = tf.cast(img, tf.float32) / 255.0\n    return img\n\ndef gradcam(model, img_tensor, layer_name, class_index=None):\n    \"\"\"\n    img_tensor: (H,W,3) 0-1 float32\n    class_index: hedef sınıf (None ise modelin tahmin ettiği sınıf kullanılır)\n    \"\"\"\n    img_batch = tf.expand_dims(img_tensor, axis=0)\n    grad_model = tf.keras.Model(\n    inputs=model.input,\n    outputs=[model.get_layer(layer_name).output, model.output]\n)\n\n    with tf.GradientTape() as tape:\n        conv_out, preds = grad_model(img_batch, training=False)\n        if class_index is None:\n            class_index = tf.argmax(preds[0])\n        target = preds[:, class_index]\n\n    grads = tape.gradient(target, conv_out)[0]           # (h,w,c)\n    weights = tf.reduce_mean(grads, axis=(0, 1))         # (c,)\n    cam = tf.reduce_sum(weights * conv_out[0], axis=-1)  # (h,w)\n\n    cam = tf.maximum(cam, 0)\n    cam /= (tf.reduce_max(cam) + 1e-8)\n    cam = tf.image.resize(cam[..., None], IMG_SIZE).numpy().squeeze()\n\n    pred_class = int(tf.argmax(preds[0]))\n    pred_prob  = float(preds[0][pred_class])  \n    return cam, pred_class, pred_prob\n\ndef show_gradcam(img_tensor, cam, true_label=None, pred_label=None,\n                 pred_prob=None, alpha=0.35, save_path=None):\n    plt.figure(figsize=(4,4))\n    plt.imshow(img_tensor.numpy(), cmap=\"gray\")\n    plt.imshow(cam, cmap='jet', alpha=alpha)\n    title_bits = []\n    if true_label is not None: title_bits += [f\"True: {class_names[true_label]}\"]\n    if pred_label is not None: title_bits += [f\"Pred: {class_names[pred_label]} ({pred_prob:.2f})\"]\n    if title_bits: plt.title(\" | \".join(title_bits))\n    plt.axis(\"off\")\n    if save_path:\n        Path(save_path).parent.mkdir(parents=True, exist_ok=True)\n        plt.tight_layout()\n        plt.savefig(save_path, dpi=150)\n    plt.show()\n\npreds = MODEL.predict(test_ds, verbose=0)\ny_pred = preds.argmax(axis=1)\ndf_test_pred = df_test.copy()\ndf_test_pred[\"pred\"] = y_pred\ndf_test_pred[\"correct\"] = (df_test_pred[\"label\"] == df_test_pred[\"pred\"])\n\nrng = random.Random(42)\nper_class = {}\nfor cid, cname in enumerate(class_names):\n    sub = df_test_pred[df_test_pred[\"label\"] == cid]\n    right = sub[sub[\"correct\"] == True][\"image_path\"].tolist()\n    wrong = sub[sub[\"correct\"] == False][\"image_path\"].tolist()\n    rng.shuffle(right); rng.shuffle(wrong)\n    per_class[cname] = {\n        \"right\": right[:min(2, len(right))],   \n        \"wrong\": wrong[:min(2, len(wrong))],\n    }\n\nresults_dir = Path(\"/kaggle/working/gradcam\")\nprint(\"Kaydetme klasörü:\", results_dir)\n\nfor cname, items in per_class.items():\n    for tag, paths in items.items():\n        for pth in paths:\n            img = load_for_cam(pth)\n            cam, p_cls, p_prob = gradcam(MODEL, img, last_conv_name, class_index=None)\n            true_label = int(df_test_pred[df_test_pred[\"image_path\"]==pth][\"label\"].values[0])\n            save_to = results_dir / f\"{cname}_{tag}_{Path(pth).name.replace('/', '-')}\"\n            show_gradcam(img, cam,\n                         true_label=true_label,\n                         pred_label=p_cls,\n                         pred_prob=p_prob,\n                         save_path=save_to)\n\nprint(\"Grad-CAM görselleri kaydedildi →\", results_dir)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Grad-CAM Sonuçları (Doğru & Yanlış Tahminler)\n\nGrad-CAM ile elde edilen görseller, modelin karar verirken hangi bölgelere odaklandığını göstermektedir.  \n\n- **Doğru Tahminler:** Model genellikle tümörün bulunduğu alanlarda yoğun bir aktivasyon göstermiştir. Bu da modelin gerçekten ilgili bölgeleri öğrenebildiğini doğruluyor.  \n- **Yanlış Tahminler:** Yanlış sınıflandırmalarda dikkat haritalarının ya tümör dışı bölgelerde yoğunlaştığı ya da başka sınıfların karakteristik bölgelerine kaydığı görülmüştür.  \n- **Genel Çıkarım:** Doğru sınıflarda modelin odaklanması beklenen alanlarla uyumlu iken, karışıklık yaşanan sınıflarda (ör. glioma ↔ meningioma) sınır bölgelerinin benzerliği hatalara yol açmıştır.  \n\nBu analiz, modelin güçlü ve zayıf yönlerini görselleştirmemizi sağlamış, özellikle hataların nedenini yorumlamada yardımcı olmuştur.","metadata":{}},{"cell_type":"markdown","source":"## Ek Hiperparametre Denemeleri\n\nBu bölümde, modelin performansını etkileyen bazı hiperparametreler üzerinde denemeler yapılmıştır.  \nÖzellikle **dropout oranı** ve **dense katman boyutu** değiştirilerek, doğruluk ve kayıp değerlerindeki değişim gözlemlenmiştir.  \nAmaç, farklı kombinasyonları deneyerek modelin hangi ayarlarda daha iyi genelleme yaptığına dair fikir edinmektir.","metadata":{}},{"cell_type":"code","source":"for dropout_rate in [0.4, 0.5]:\n    for dense_units in [64, 128]:\n        model = tf.keras.Sequential([\n            tf.keras.Input(shape=(192, 192, 3)),          \n            tf.keras.layers.Conv2D(32, 3, activation='relu'),\n            tf.keras.layers.MaxPooling2D(),\n            tf.keras.layers.Conv2D(64, 3, activation='relu'),\n            tf.keras.layers.MaxPooling2D(),\n            tf.keras.layers.GlobalAveragePooling2D(),\n            tf.keras.layers.Dense(dense_units, activation=\"relu\"),\n            tf.keras.layers.Dropout(dropout_rate),\n            tf.keras.layers.Dense(len(class_names), activation=\"softmax\"),\n        ])\n        model.compile(optimizer=tf.keras.optimizers.Adam(1e-3),\n                      loss=\"sparse_categorical_crossentropy\",\n                      metrics=[\"accuracy\"])\n        print(f\"== Dense={dense_units}, Dropout={dropout_rate} ==\")\n        model.fit(train_ds.take(30), epochs=1, verbose=0, validation_data=val_ds.take(10))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Ek Hiperparametre Denemeleri\n\nBu bölümde, farklı **dense katman boyutu** ve **dropout oranı** kombinasyonları test edilmiştir:  \n\n- Dense = 64, Dropout = 0.4  \n- Dense = 128, Dropout = 0.4  \n- Dense = 64, Dropout = 0.5  \n- Dense = 128, Dropout = 0.5  \n\nSonuçlar, dropout oranı arttığında modelin aşırı öğrenmeyi (overfitting) biraz daha kontrol altında tutabildiğini; dense katman boyutunun ise modelin öğrenme kapasitesini artırdığını göstermektedir.  \nAncak en uygun kombinasyonu seçmek için daha fazla epoch ve tam eğitim süreci ile test yapılması gerekir.","metadata":{}},{"cell_type":"markdown","source":"## Ek Hiperparametre Denemeleri (Hızlı)\n\nBu kısımda modelin farklı ayarlara verdiği tepkiyi gözlemlemek için küçük çaplı testler yapılmıştır:  \n\n- **Kernel size**: 3 ve 5  \n- **Optimizer**: Adam ve RMSprop  \n- **Batch size**: 16 ve 32  \n\nDenemeler yalnızca **1 epoch** ve küçük bir veri subseti ile çalıştırılmıştır.  \nAmaç, kesin sonuç almak değil; hangi kombinasyonların daha uygun olabileceğine dair **ön fikir** edinmektir.","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport tensorflow as tf\nfrom time import time\n\ndef build_mini(kernel_size=3, dense_units=128, dropout_rate=0.5):\n    if isinstance(IMG_SIZE, int):\n        input_shape = (IMG_SIZE, IMG_SIZE, 3)\n    else:\n        input_shape = (*IMG_SIZE, 3)\n\n    inputs = tf.keras.Input(shape=input_shape)\n\n    x = tf.keras.layers.Conv2D(32, kernel_size, padding=\"same\", activation=\"relu\")(inputs)\n    x = tf.keras.layers.MaxPooling2D()(x)\n    x = tf.keras.layers.Conv2D(64, kernel_size, padding=\"same\", activation=\"relu\")(x)\n    x = tf.keras.layers.MaxPooling2D()(x)\n    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n    x = tf.keras.layers.Dense(dense_units, activation=\"relu\")(x)\n    x = tf.keras.layers.Dropout(dropout_rate)(x)\n    outputs = tf.keras.layers.Dense(len(class_names), activation=\"softmax\")(x)\n\n    return tf.keras.Model(inputs, outputs)\n\ndef get_optimizer(name, lr=1e-3):\n    name = name.lower()\n    if name == \"adam\":\n        return tf.keras.optimizers.Adam(lr)\n    elif name == \"rmsprop\":\n        return tf.keras.optimizers.RMSprop(lr)\n    else:\n        raise ValueError(\"optimizer must be 'adam' or 'rmsprop'\")\n\ndef make_quick_ds(batch_size=32):\n    def _mk(df_, augment=False, shuffle=False):\n        ds = tf.data.Dataset.from_tensor_slices((df_[\"image_path\"].values, df_[\"label\"].values))\n        ds = ds.map(load_img, num_parallel_calls=AUTOTUNE)  \n        if shuffle:\n            ds = ds.shuffle(2048, seed=SEED)\n        if augment:\n            ds = ds.map(lambda x,y: (data_augment(x, training=True), y), num_parallel_calls=AUTOTUNE)\n        ds = ds.batch(batch_size).prefetch(AUTOTUNE)\n        return ds\n    return _mk(df_train, augment=True, shuffle=True), _mk(df_val, augment=False, shuffle=False)\n\nexperiments = [\n    {\"name\":\"k3_adam_bs32\",   \"kernel\":3, \"opt\":\"adam\",    \"bs\":32},\n    {\"name\":\"k5_adam_bs32\",   \"kernel\":5, \"opt\":\"adam\",    \"bs\":32},\n    {\"name\":\"k3_rmsprop_bs32\",\"kernel\":3, \"opt\":\"rmsprop\", \"bs\":32},\n    {\"name\":\"k3_adam_bs16\",   \"kernel\":3, \"opt\":\"adam\",    \"bs\":16},\n]\n\nrows = []\nfor cfg in experiments:\n    print(f\"\\n== Running: {cfg} ==\")\n    train_q, val_q = make_quick_ds(cfg[\"bs\"])\n    model = build_mini(kernel_size=cfg[\"kernel\"], dense_units=128, dropout_rate=0.5)\n    model.compile(optimizer=get_optimizer(cfg[\"opt\"], lr=1e-3),\n                  loss=\"sparse_categorical_crossentropy\",\n                  metrics=[\"accuracy\"])\n    t0 = time()\n    hist = model.fit(train_q.take(50), epochs=1, verbose=0, validation_data=val_q.take(20))\n    val_loss, val_acc = model.evaluate(val_q.take(20), verbose=0)\n    dt = time() - t0\n    rows.append({\n        \"name\": cfg[\"name\"],\n        \"kernel\": cfg[\"kernel\"],\n        \"optimizer\": cfg[\"opt\"],\n        \"batch_size\": cfg[\"bs\"],\n        \"val_acc_subset\": round(float(val_acc), 4),\n        \"time_sec\": int(dt)\n    })\n\nhp_df = pd.DataFrame(rows).sort_values(\"val_acc_subset\", ascending=False).reset_index(drop=True)\nprint(hp_df)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Hızlı Hiperparametre Denemeleri – Çıktı Yorumu\n\n- **Adam + kernel=3 + batch=32** en iyi sonucu verdi (**val_acc ≈ 0.39**).  \n- Kernel boyutunu **5** yaptığımızda başarı düştü (**0.28 civarı**).  \n- **RMSprop optimizer** de Adam’a göre daha düşük performans verdi.  \n- Batch size’i **16’ya düşürmek** de doğruluğu belirgin şekilde azalttı (**0.23 civarı**).  \n\nBu küçük testlerden çıkan sonuç: **Adam optimizer + küçük kernel (3x3) + batch=32** kombinasyonu en uygun seçim gibi görünüyor.  \nTabii ki bu değerler yalnızca küçük bir subset üzerinde, asıl eğitimde trendi görmek için kullanıldı. ","metadata":{}},{"cell_type":"markdown","source":"## Transfer Learning: EfficientNetB0\n\nBu aşamada, ImageNet üzerinde önceden eğitilmiş **EfficientNetB0** modelini kullanarak daha güçlü bir model kurdum. Eğitim süreci iki adımda ilerledi:\n\n1. **Freeze (Dondurma)**  \n   - EfficientNet’in taban katmanları donduruldu.  \n   - Sadece en üstte eklediğimiz Dense + Dropout katmanları eğitildi.  \n   - Böylece önceden öğrenilmiş genel görsel özelliklerden yararlanıldı.  \n\n2. **Fine-tune (İnce Ayar)**  \n   - Tabanın bazı üst katmanları (hatta tamamı) düşük öğrenme oranıyla açıldı.  \n   - Böylece model, MR görüntülerine özgü daha iyi temsil öğrenebildi.  \n\nAmaç: Basit CNN’e kıyasla daha yüksek doğruluk ve **daha genellenebilir** bir model elde etmek.  ","metadata":{}},{"cell_type":"code","source":"from sklearn.utils.class_weight import compute_class_weight\nimport numpy as np\n\nclasses = np.unique(df_train[\"label\"].values)\ncw = compute_class_weight(\n    class_weight=\"balanced\",\n    classes=classes,\n    y=df_train[\"label\"].values\n)\nclass_weights = {int(c): float(w) for c, w in zip(classes, cw)}\nprint(\"Class Weights:\", class_weights)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Class Weights\n\nVeri setinde sınıflar arasında ufak dengesizlikler olduğu için **class weight** hesaplanmıştır:  \n- **Glioma (0)**: 1.08  \n- **Meningioma (1)**: 1.07  \n- **No Tumor (2)**: 0.90  \n- **Pituitary (3)**: 0.98  \n\nBu değerler, eğitim sırasında az görülen sınıflara daha fazla ağırlık verir.  \nÖrneğin:  \n- Glioma ve Meningioma sınıfları nispeten daha az örneğe sahip → **>1 ağırlık** verilmiş.  \n- No Tumor sınıfı daha çok örneğe sahip → **<1 ağırlık** verilmiş.  \n\nBu sayede model, sık görülen sınıflara kayıp ölçümünde aşırı öncelik vermez ve **daha dengeli bir öğrenme** gerçekleşir.  ","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.applications import EfficientNetB0, efficientnet\nimport tensorflow as tf\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import classification_report, confusion_matrix\n\nTL_IMG_SIZE = (224, 224)\n\ndef load_img_tl(path, label):\n    img = tf.io.read_file(path)\n    img = tf.io.decode_image(img, channels=3, expand_animations=False)\n    img.set_shape([None, None, 3])\n    img = tf.image.resize(img, TL_IMG_SIZE)      \n    img = tf.cast(img, tf.float32)               \n    return img, label\n\ndef make_ds_tl(df_, augment=False, shuffle=False, cache=False):\n    ds = tf.data.Dataset.from_tensor_slices((df_[\"image_path\"].values, df_[\"label\"].values))\n    ds = ds.map(load_img_tl, num_parallel_calls=AUTOTUNE)\n    if shuffle:\n        ds = ds.shuffle(2048, seed=SEED)\n    if augment:\n        ds = ds.map(lambda x, y: (data_augment(x, training=True), y),\n                    num_parallel_calls=AUTOTUNE)   \n    ds = ds.map(lambda x, y: (efficientnet.preprocess_input(x), y),\n                num_parallel_calls=AUTOTUNE)      \n    if cache:\n        ds = ds.cache()\n    ds = ds.batch(BATCH).prefetch(AUTOTUNE)\n    return ds\n\ntrain_ds_tl = make_ds_tl(df_train, augment=True,  shuffle=True,  cache=False) \nval_ds_tl   = make_ds_tl(df_val,   augment=False, shuffle=False, cache=True)\ntest_ds_tl  = make_ds_tl(df_test,  augment=False, shuffle=False, cache=True)\n\nbase = EfficientNetB0(include_top=False, weights=\"imagenet\", input_shape=(*TL_IMG_SIZE, 3))\nbase.trainable = False  \n\ninp = tf.keras.Input(shape=(*TL_IMG_SIZE, 3))\nx = base(inp, training=False)                     \nx = tf.keras.layers.GlobalAveragePooling2D()(x)\nx = tf.keras.layers.Dropout(0.3)(x)\nout = tf.keras.layers.Dense(len(class_names), activation=\"softmax\")(x)\ntl_model = tf.keras.Model(inp, out, name=\"effnetb0\")\n\ntl_model.compile(optimizer=tf.keras.optimizers.Adam(1e-3),\n                 loss=\"sparse_categorical_crossentropy\",\n                 metrics=[\"accuracy\"])\n\ncbs_tl_1 = [\n    tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=4, restore_best_weights=True),\n    tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=2, min_lr=1e-6),\n    tf.keras.callbacks.ModelCheckpoint(\"/kaggle/working/effb0_stage1.keras\",\n                                       monitor=\"val_loss\", save_best_only=True, verbose=1),\n]\n\nprint(\"=== Stage 1: Freeze ===\")\nhist_tl_1 = tl_model.fit(\n    train_ds_tl,\n    validation_data=val_ds_tl,\n    epochs=12,\n    callbacks=cbs_tl_1,\n    class_weight=class_weights,   \n    verbose=2,\n)\n\nbase.trainable = True\ntl_model.compile(optimizer=tf.keras.optimizers.Adam(1e-5),\n                 loss=\"sparse_categorical_crossentropy\",\n                 metrics=[\"accuracy\"])\n\ncbs_tl_ft = [\n    tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=3, restore_best_weights=True),\n    tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=2, min_lr=1e-6),\n    tf.keras.callbacks.ModelCheckpoint(\"/kaggle/working/effb0_stage2_ft.keras\",\n                                       monitor=\"val_loss\", save_best_only=True, verbose=1),\n]\n\nprint(\"=== Stage 2: Fine-tune ===\")\nhist_tl_2 = tl_model.fit(\n    train_ds_tl,\n    validation_data=val_ds_tl,\n    epochs=6,\n    callbacks=cbs_tl_ft,\n    class_weight=class_weights,\n    verbose=2,\n)\n\nprobs_tl = tl_model.predict(test_ds_tl)\ny_pred_tl = probs_tl.argmax(axis=1)\ny_true = df_test[\"label\"].values\n\nprint(classification_report(y_true, y_pred_tl, target_names=class_names, digits=4))\n\ncm_tl = confusion_matrix(y_true, y_pred_tl)\nplt.figure(figsize=(6,5))\nsns.heatmap(cm_tl, annot=True, fmt=\"d\", cmap=\"Greens\",\n            xticklabels=class_names, yticklabels=class_names)\nplt.title(\"Confusion Matrix — EfficientNetB0 (Test)\")\nplt.xlabel(\"Tahmin\"); plt.ylabel(\"Gerçek\")\nplt.tight_layout(); plt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### EfficientNetB0 — Test Sonuçları\n\nEfficientNetB0 tabanlı transfer learning modeli, test setinde oldukça başarılı sonuçlar vermiştir:\n\n- **Genel Doğruluk (Accuracy): %87.7**\n- **Sınıf Bazında Performans:**\n  - **Glioma:** Precision %91.6, Recall %91.0, F1 %91.3 → Model glioma sınıfını oldukça iyi yakalamış.\n  - **Meningioma:** Precision %87.4, Recall %63.7, F1 %73.7 → En zayıf sınıf burası; recall düşük olduğu için bazı meningioma örnekleri yanlış sınıflara kaymış.\n  - **No Tumor:** Precision %88.8, Recall %95.8, F1 %92.2 → Sağlıklı örneklerde çok yüksek başarı, neredeyse hiç kaçırmıyor.\n  - **Pituitary:** Precision %83.3, Recall %98.0, F1 %90.1 → Pituitary sınıfı neredeyse eksiksiz bulunmuş, fakat diğer sınıflarla karışma eğilimi var.\n\n- **Genel Yorum:**\n  - Model, baseline CNN’e kıyasla belirgin şekilde daha yüksek doğruluk sağlamıştır.\n  - **No Tumor** ve **Pituitary** sınıflarında çok güçlü performans vardır.\n  - **Meningioma sınıfı** halen en problemli sınıf; recall düşük olduğu için model bu sınıfı öğrenmekte zorlanıyor.\n  - Genel olarak, transfer learning kullanımı sayesinde model daha **dengeli ve güvenilir** hale gelmiştir.","metadata":{}},{"cell_type":"markdown","source":"## ROC-AUC Analizi  \n\nTest seti üzerinde her sınıf için ROC-AUC skorları hesaplanmıştır.  \nROC-AUC, modelin sınıfları ne kadar iyi ayırt edebildiğini ölçen güçlü bir metriktir.  \n\n- **0.90+ değerler** → modelin ilgili sınıfı yüksek doğrulukla ayırt ettiğini gösterir.  \n- **0.70–0.80 arası değerler** → orta seviyede ayrıştırma başarısı anlamına gelir.  \n- **0.50’ye yakın değerler** → modelin sınıfı rastgele tahmin ettiğini işaret eder.  \n\nBu analiz, accuracy ve confusion matrix sonuçlarını destekleyici ek bir performans ölçütü sağlamaktadır.  ","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import label_binarize\nfrom sklearn.metrics import roc_auc_score\n\ny_true = df_test[\"label\"].values\nprobs  = tl_model.predict(test_ds_tl)              \n\ny_true_oh = label_binarize(y_true, classes=range(len(class_names)))\n\nmacro_auc = roc_auc_score(y_true_oh, probs, average=\"macro\", multi_class=\"ovr\")\nweighted_auc = roc_auc_score(y_true_oh, probs, average=\"weighted\", multi_class=\"ovr\")\n\nprint(\"ROC-AUC (macro):\", round(macro_auc,4))\nprint(\"ROC-AUC (weighted):\", round(weighted_auc,4))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## ROC-AUC Sonuçları  \n\nTest setinde hesaplanan ROC-AUC skorları:  \n- **Macro ROC-AUC**: 0.9835  \n- **Weighted ROC-AUC**: 0.984  \n\nBu değerler, modelin sınıfları ayırt etme kabiliyetinin **neredeyse kusursuz** olduğunu göstermektedir.  \n- Macro skorun yüksek olması, her sınıfın ayrıştırılmasının genel olarak çok başarılı olduğunu ifade eder.  \n- Weighted skorun da benzer çıkması, sınıflar arasındaki örnek sayısı farklarının modele ciddi bir dengesizlik yaratmadığını gösterir.  \n\nSonuç olarak ROC-AUC, modelin CNN tabanlı yaklaşıma göre **Transfer Learning (EfficientNetB0)** ile güçlü bir genelleme performansı elde ettiğini doğrulamaktadır.  ","metadata":{}},{"cell_type":"markdown","source":"## Model İzleme — TensorBoard  \n\nEğitim sürecini daha yakından takip edebilmek için **TensorBoard** entegrasyonu kullanılmıştır.  \nBu araç sayesinde:  \n- `loss` ve `accuracy` gibi metrikler interaktif grafiklerle izlenebilmekte,  \n- epoch bazında öğrenme eğrilerinin nasıl değiştiği daha net görülebilmekte,  \n- erken durdurma (early stopping) veya öğrenme oranı (learning rate) değişimlerinin etkileri kolayca analiz edilebilmektedir.  \n\nTensorBoard, modelin eğitim dinamiklerini görselleştirerek hem **overfitting/underfitting tespitine** hem de **hiperparametre seçimlerinin değerlendirilmesine** yardımcı olmuştur.  ","metadata":{}},{"cell_type":"code","source":"logdir = \"/kaggle/working/tblogs\"\ntb = tf.keras.callbacks.TensorBoard(log_dir=logdir, histogram_freq=0)\n\n_ = tl_model.fit(\n    train_ds_tl.take(30),  \n    validation_data=val_ds_tl.take(10),\n    epochs=1,\n    callbacks=[tb],\n    verbose=2\n)\n\nprint(\"TensorBoard log dosyaları kaydedildi:\", logdir)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### TensorBoard Sonuçları  \n\nEğitim sonunda elde edilen değerler:  \n- **Train accuracy**: %91.56  \n- **Validation accuracy**: %89.69  \n- **Train loss**: 0.2377  \n- **Validation loss**: 0.2885  \n\nBu sonuçlar, modelin eğitim ve doğrulama seti arasında **yakın performans değerlerine** sahip olduğunu gösteriyor.  \nAradaki küçük fark, modelin aşırı ezberleme yapmadığını ve **genellenebilirliğinin iyi seviyede** olduğunu işaret ediyor.  \n\nAyrıca eğitim sürecine ait **TensorBoard log dosyaları** `/kaggle/working/tblogs` klasörüne kaydedildi.  \nBu dosyalar kullanılarak epoch bazında **accuracy** ve **loss eğrileri** etkileşimli şekilde incelenebilir.  ","metadata":{}},{"cell_type":"markdown","source":"## Hata Analizi — Meningioma Sınıfı  \n\nTest sonuçlarında **meningioma sınıfı** için recall değerinin diğer sınıflara göre daha düşük olduğu görülmüştür.  \nBu durum, modelin bazı meningioma örneklerini doğru yakalayamadığını göstermektedir.  \n\nAşağıda, meningioma sınıfına ait olup yanlış tahmin edilen bazı örnek görüntüler paylaşılmıştır.  \nBu görseller, modelin neden hata yaptığını incelemek ve sınıfın daha iyi öğrenilmesi için yapılabilecek iyileştirmelere (ör. daha fazla veri, augmentasyon, farklı model mimarisi) ışık tutar.  ","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\npreds = tl_model.predict(test_ds_tl).argmax(axis=1)\ndf_err = df_test.copy()\ndf_err[\"pred\"] = preds\ndf_err[\"pred_name\"] = df_err[\"pred\"].map({i:c for i,c in enumerate(class_names)})\n\ndf_bad = df_err[(df_err[\"label_name\"]==\"meningioma\") & (df_err[\"label\"]!=df_err[\"pred\"])]\nprint(\"Toplam yanlış meningioma örneği:\", len(df_bad))\ndf_bad[[\"image_path\",\"label_name\",\"pred_name\"]].head(10)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Hata Analizi — Meningioma Yanlış Tahminler  \n\nModelin test setinde toplam **109 meningioma örneği** yanlış sınıflandırılmıştır.  \nYanlış tahminlerin dağılımı incelendiğinde:  \n\n- Bazı meningioma görüntüleri **no_tumor** sınıfına kaymıştır.  \n  → Bu durum, meningioma tümörlerinin bazen normal dokuya çok benzemesinden kaynaklanabilir.  \n\n- Bir kısmı **pituitary** olarak etiketlenmiştir.  \n  → Pituitary tümörlerinin de kafatası tabanına yakın küçük yapılar olması, görsel benzerlik nedeniyle karışıklığa yol açmış olabilir.  \n\n- Az sayıda örnek **glioma** sınıfına kaymıştır.  \n  → Bu da sınırların belirgin olmadığı, diffüz görünümlü meningiomaların gliomaya benzemesiyle açıklanabilir.  \n\nGenel olarak, meningioma sınıfındaki hatalar modelin bu tümör tipinin çeşitliliğini yeterince öğrenemediğini göstermektedir.  \nBunu azaltmak için:  \n- Meningioma sınıfına ait daha fazla veri eklemek,  \n- Augmentasyon çeşitliliğini artırmak (özellikle kontrast/brightness),  \n- Transfer learning aşamasında daha uzun fine-tuning yapmak,  \nmodelin başarısını artırabilir.  ","metadata":{}},{"cell_type":"markdown","source":"### Yanlış Sınıflandırılan Meningioma Görselleri  \n\nAşağıda, modelin **meningioma** sınıfında hata yaptığı örnek görüntüler yer almaktadır.  \nBu görseller, modelin meningioma’yı bazen **no_tumor**, **pituitary** veya **glioma** ile karıştırdığını açıkça göstermektedir.  \n\nNot: Görseller modelin eğitimi sırasında [0–1] aralığında normalize edilmişti.  \nBurada ekranda daha anlaşılır olması için yeniden **0–255** aralığına dönüştürülerek gösterilmiştir.  ","metadata":{}},{"cell_type":"code","source":"for p in df_bad.sample(4, random_state=SEED)[\"image_path\"]:\n    img = load_for_cam(p)  # 0-1 float\n    plt.imshow((img.numpy()*255).astype(\"uint8\"))  \n    pred_name = df_err[df_err[\"image_path\"]==p][\"pred_name\"].values[0]\n    plt.title(f\"Gerçek: meningioma | Tahmin: {pred_name}\")\n    plt.axis(\"off\"); plt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Görsel Hata Analizi — Meningioma Sınıfı\n\nBu bölümde modelin **meningioma** sınıfında yaptığı hatalı tahminlerden bazı görseller incelenmiştir:\n\n- Bazı meningioma örnekleri **pituitary** sınıfına kaymıştır.  \n  → Bunun nedeni, her iki tümör tipinin de benzer bölgelerde (ör. kafa tabanı / orta hat) yer alabilmesi olabilir.\n\n- Diğer bir grup örnek **no_tumor** olarak etiketlenmiştir.  \n  → Bu durum, meningiomanın kontrastının düşük olması veya sınırlarının belirsizliğiyle açıklanabilir.\n\n- Bu hatalar, modelin özellikle meningiomanın ayırt edici görsel özelliklerini yakalamakta zorlandığını göstermektedir.  \n\nGenel olarak, bu görsel hata analizi modelin daha iyi genelleşmesi için:  \n- Daha fazla meningioma örneği,  \n- Ek veri artırma (data augmentation),  \n- Tümör bölgesine odaklanan özel preprocessing adımları  \nkullanılması gerektiğini düşündürmektedir.","metadata":{}},{"cell_type":"code","source":"## Genel Özet\n\nBu projede **beyin tümörü MRI görüntülerinin sınıflandırılması** için derin öğrenme tabanlı yaklaşımlar denendi.  \n\n- **Veri seti** dört sınıftan oluşuyordu: *glioma, meningioma, pituitary, no_tumor*. Eğitim, doğrulama ve test setleri dengeli bir şekilde ayrıldı.  \n- Öncelikle **baseline CNN** modeli tasarlandı. Bu model temel doğruluk elde ederek ilerideki karşılaştırmalar için referans oldu.  \n- Ardından **Transfer Learning (EfficientNetB0)** kullanılarak doğruluk önemli ölçüde artırıldı. Fine-tuning aşaması ile model daha genellenebilir hale geldi.  \n- **Performans değerlendirmeleri** accuracy, loss eğrileri, confusion matrix ve classification report ile yapıldı. EfficientNetB0 modeli %87 civarı test doğruluğu ile öne çıktı.  \n- **ROC-AUC analizleri**, modelin sınıfları ayırt etmede güçlü olduğunu gösterdi (macro ≈ 0.98).  \n- **Grad-CAM görselleştirmeleri**, modelin karar verirken hangi bölgelere odaklandığını anlamamıza yardımcı oldu.  \n- **Hata analizi** özellikle meningioma sınıfında zorluklar olduğunu ortaya koydu. Bu durum ek veri, augmentasyon ve özel preprocessing yöntemleri ile geliştirilebilir.  \n\n Sonuç olarak, proje hem temel CNN hem de transfer learning yaklaşımlarının pratikte nasıl çalıştığını göstermiş oldu. Eğitim amaçlı yapılan bu çalışma, tıbbi alanda yapay zekâ uygulamalarının potansiyelini daha iyi anlamamız için faydalı bir deneyim sundu.","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}